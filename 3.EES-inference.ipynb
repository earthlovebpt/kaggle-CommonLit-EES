{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c337919d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:41:32.114380Z",
     "iopub.status.busy": "2023-08-03T08:41:32.113980Z",
     "iopub.status.idle": "2023-08-03T08:41:46.914838Z",
     "shell.execute_reply": "2023-08-03T08:41:46.913863Z"
    },
    "papermill": {
     "duration": 14.81173,
     "end_time": "2023-08-03T08:41:46.917328",
     "exception": false,
     "start_time": "2023-08-03T08:41:32.105598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger, CSVLogger\n",
    "import glob\n",
    "import json\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69942c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:41:46.928835Z",
     "iopub.status.busy": "2023-08-03T08:41:46.927270Z",
     "iopub.status.idle": "2023-08-03T08:41:46.955855Z",
     "shell.execute_reply": "2023-08-03T08:41:46.954549Z"
    },
    "papermill": {
     "duration": 0.03613,
     "end_time": "2023-08-03T08:41:46.958038",
     "exception": false,
     "start_time": "2023-08-03T08:41:46.921908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "with open('/kaggle/input/bert-train/config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "    \n",
    "torch.manual_seed(config[\"SEED\"])\n",
    "torch.cuda.manual_seed(config[\"SEED\"])\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "pl.seed_everything(config[\"SEED\"])\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba0ba0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:41:46.968692Z",
     "iopub.status.busy": "2023-08-03T08:41:46.967827Z",
     "iopub.status.idle": "2023-08-03T08:41:47.096871Z",
     "shell.execute_reply": "2023-08-03T08:41:47.095793Z"
    },
    "papermill": {
     "duration": 0.137452,
     "end_time": "2023-08-03T08:41:47.099940",
     "exception": false,
     "start_time": "2023-08-03T08:41:46.962488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission shape: (4, 3)\n",
      "prompts_train shape: (4, 4)\n",
      "summaries_test shape: (4, 3)\n",
      "summaries_train shape: (7165, 5)\n",
      "prompts_test shape: (2, 4)\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id            text\n",
       "0  000000ffffff    abc123  Example text 1\n",
       "1  111111eeeeee    def789  Example text 2\n",
       "2  222222cccccc    abc123  Example text 3\n",
       "3  333333dddddd    def789  Example text 4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\")\n",
    "prompts_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\n",
    "prompts_test  = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\n",
    "\n",
    "print(f'sample_submission shape: {sample_submission.shape}')\n",
    "print(f'prompts_train shape: {prompts_train.shape}')\n",
    "print(f'summaries_test shape: {summaries_test.shape}')\n",
    "print(f'summaries_train shape: {summaries_train.shape}')\n",
    "print(f'prompts_test shape: {prompts_test.shape}')\n",
    "print('-'*90)\n",
    "\n",
    "# summaries_train = pd.merge(summaries_train, prompts_train, on=\"prompt_id\")\n",
    "# summaries_test = pd.merge(summaries_test, prompts_test, on=\"prompt_id\")\n",
    "summaries_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a535759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:41:47.110979Z",
     "iopub.status.busy": "2023-08-03T08:41:47.110649Z",
     "iopub.status.idle": "2023-08-03T08:41:47.118553Z",
     "shell.execute_reply": "2023-08-03T08:41:47.117528Z"
    },
    "papermill": {
     "duration": 0.015524,
     "end_time": "2023-08-03T08:41:47.120604",
     "exception": false,
     "start_time": "2023-08-03T08:41:47.105080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class MCRMSELoss(nn.Module):\n",
    "    def __init__(self, num_scored=3):\n",
    "        super().__init__()\n",
    "        self.rmse = RMSELoss()\n",
    "        self.num_scored = num_scored\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        score = 0\n",
    "        for i in range(self.num_scored):\n",
    "            score += self.rmse(yhat[:,  i], y[:, i]) / self.num_scored\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbff6172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:41:47.131190Z",
     "iopub.status.busy": "2023-08-03T08:41:47.130905Z",
     "iopub.status.idle": "2023-08-03T08:41:47.148188Z",
     "shell.execute_reply": "2023-08-03T08:41:47.147328Z"
    },
    "papermill": {
     "duration": 0.025046,
     "end_time": "2023-08-03T08:41:47.150175",
     "exception": false,
     "start_time": "2023-08-03T08:41:47.125129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        model_config = AutoConfig.from_pretrained(\n",
    "            config[\"model_dir\"], \n",
    "            num_labels = 2,\n",
    "            problem_type = \"regression\",\n",
    "            hidden_dropout_prob = config[\"hidden_dropout_prob\"], \n",
    "            attention_probs_dropout_prob = config[\"attention_probs_dropout_prob\"],\n",
    "            classifier_dropout = config[\"classifier_dropout\"],\n",
    "        )\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(config[\"model_dir\"], config=model_config)\n",
    "        if config[\"loss\"] == \"mse\":\n",
    "            self.loss_fn = torch.nn.MSELoss()\n",
    "        elif config[\"loss\"] == \"mcrmse\":\n",
    "            self.loss_fn = MCRMSELoss(num_scored=2)\n",
    "        self.config = config\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.lr = config[\"lr\"]\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.model(input_ids, \n",
    "                            attention_mask = attention_mask, \n",
    "                            token_type_ids = token_type_ids)\n",
    "        return output\n",
    "    \n",
    "    def step(self, batch):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        outputs = self(input_ids, attention_mask, token_type_ids)\n",
    "        targets = batch['targets']\n",
    "        loss = self.loss_fn(outputs[\"logits\"], targets)\n",
    "        content, wording = compute_RMSE(outputs[\"logits\"], targets)\n",
    "        return loss, content, wording\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, content, wording = self.step(batch)\n",
    "        self.training_step_outputs.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, content, wording = self.step(batch)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.log(\"content_error\", content) \n",
    "        self.log(\"wording_error\", wording) \n",
    "        self.log(\"total_error\", (content+wording)/2)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        loss_mean = torch.stack(self.training_step_outputs).mean()\n",
    "        self.log(f'ep_train_loss_fold{self.config[\"fold\"]}', loss_mean, prog_bar=True)\n",
    "        self.training_step_outputs.clear()\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss_mean = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(f'ep_val_loss_fold{self.config[\"fold\"]}', loss_mean, prog_bar=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        model = self.model\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': self.config[\"weight_decay\"]},\n",
    "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optim = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62591fef",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-03T08:41:47.161261Z",
     "iopub.status.busy": "2023-08-03T08:41:47.160473Z",
     "iopub.status.idle": "2023-08-03T08:41:47.270057Z",
     "shell.execute_reply": "2023-08-03T08:41:47.269063Z"
    },
    "papermill": {
     "duration": 0.117489,
     "end_time": "2023-08-03T08:41:47.272441",
     "exception": false,
     "start_time": "2023-08-03T08:41:47.154952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitTestDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_list, max_len):\n",
    "        self.dataframe = dataframe\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config[\"model_dir\"])\n",
    "        self.text = dataframe['text'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        text = row[\"text\"]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text.lower(),\n",
    "            truncation=\"longest_first\",\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attention_mask = inputs['attention_mask'].flatten()\n",
    "        token_type_ids = inputs['token_type_ids'].flatten()\n",
    "        \n",
    "        return {'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'token_type_ids': token_type_ids}\n",
    "    \n",
    "\n",
    "test_dataset = CommonLitTestDataset(summaries_test,\n",
    "                                    target_list = config[\"target_list\"],\n",
    "                                    max_len = config[\"MAX_LEN\"],\n",
    "                                    )\n",
    "\n",
    "test_data_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42830ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:41:47.283075Z",
     "iopub.status.busy": "2023-08-03T08:41:47.282750Z",
     "iopub.status.idle": "2023-08-03T08:42:06.382644Z",
     "shell.execute_reply": "2023-08-03T08:42:06.381581Z"
    },
    "papermill": {
     "duration": 19.107845,
     "end_time": "2023-08-03T08:42:06.385072",
     "exception": false,
     "start_time": "2023-08-03T08:41:47.277227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model_list = []\n",
    "# for i in glob.glob(\"/kaggle/input/bert-train/fold*/*\"):\n",
    "#     model = CommonLitModel(config)\n",
    "#     model.load_state_dict(torch.load(i)[\"state_dict\"])\n",
    "#     model_list.append(model)\n",
    "\n",
    "i = \"/kaggle/input/bert-train/full_train/epoch=5.ckpt\"\n",
    "model = CommonLitModel(config)\n",
    "model.load_state_dict(torch.load(i)[\"state_dict\"])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b670340b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:42:06.396425Z",
     "iopub.status.busy": "2023-08-03T08:42:06.396128Z",
     "iopub.status.idle": "2023-08-03T08:42:06.403104Z",
     "shell.execute_reply": "2023-08-03T08:42:06.402119Z"
    },
    "papermill": {
     "duration": 0.014884,
     "end_time": "2023-08-03T08:42:06.405261",
     "exception": false,
     "start_time": "2023-08-03T08:42:06.390377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            input_ids = batch['input_ids'].to(device, dtype = torch.long).to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device, dtype = torch.long).to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long).to(device)\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            preds.extend(outputs[\"logits\"].cpu().detach().numpy().tolist())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94a269a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:42:06.415878Z",
     "iopub.status.busy": "2023-08-03T08:42:06.415612Z",
     "iopub.status.idle": "2023-08-03T08:42:07.975799Z",
     "shell.execute_reply": "2023-08-03T08:42:07.974873Z"
    },
    "papermill": {
     "duration": 1.568297,
     "end_time": "2023-08-03T08:42:07.978128",
     "exception": false,
     "start_time": "2023-08-03T08:42:06.409831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>-0.222112</td>\n",
       "      <td>-0.263311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>-0.222112</td>\n",
       "      <td>-0.263311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>-0.222112</td>\n",
       "      <td>-0.263311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>-0.222112</td>\n",
       "      <td>-0.263311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id   content   wording\n",
       "0  000000ffffff -0.222112 -0.263311\n",
       "1  111111eeeeee -0.222112 -0.263311\n",
       "2  222222cccccc -0.222112 -0.263311\n",
       "3  333333dddddd -0.222112 -0.263311"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = []\n",
    "# for model in model_list:\n",
    "#     model = model.to(device)\n",
    "#     y_pred_i = test_model(model, test_data_loader)\n",
    "#     y_pred.append(y_pred_i)\n",
    "# y_pred = np.mean(y_pred, axis=0)\n",
    "\n",
    "y_pred = test_model(model, test_data_loader)\n",
    "    \n",
    "pred_data = pd.DataFrame({col: [col[idx] for col in y_pred]\n",
    "                          for idx,col in enumerate(config[\"target_list\"])})\n",
    "for col in sample_submission.columns[1:]:\n",
    "    sample_submission[col] = pred_data[col]\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c64a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T08:42:07.990762Z",
     "iopub.status.busy": "2023-08-03T08:42:07.990085Z",
     "iopub.status.idle": "2023-08-03T08:42:07.997351Z",
     "shell.execute_reply": "2023-08-03T08:42:07.996393Z"
    },
    "papermill": {
     "duration": 0.01591,
     "end_time": "2023-08-03T08:42:07.999489",
     "exception": false,
     "start_time": "2023-08-03T08:42:07.983579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed040dc0",
   "metadata": {
    "papermill": {
     "duration": 0.005249,
     "end_time": "2023-08-03T08:42:08.010524",
     "exception": false,
     "start_time": "2023-08-03T08:42:08.005275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ed312",
   "metadata": {
    "papermill": {
     "duration": 0.00525,
     "end_time": "2023-08-03T08:42:08.021372",
     "exception": false,
     "start_time": "2023-08-03T08:42:08.016122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e8bdb",
   "metadata": {
    "papermill": {
     "duration": 0.004726,
     "end_time": "2023-08-03T08:42:08.031409",
     "exception": false,
     "start_time": "2023-08-03T08:42:08.026683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.691115,
   "end_time": "2023-08-03T08:42:10.903103",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-03T08:41:22.211988",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
